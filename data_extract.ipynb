{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setup for PRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "client_id = '0X3RFkechF94pb0jhrBaBA'\n",
    "client_secret = '_A0RRGRXo4w_rWKm6mGYeoqqvW2NnA'\n",
    "user_agent='MyRedditBot:v1.0 (by u/Healthy-Pollution929)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the PRAW client\n",
    "reddit = praw.Reddit(client_id=client_id, client_secret=client_secret, user_agent=user_agent)\n",
    "\n",
    "def fetch_comments(subreddit_name, search_query, time_filter='year', post_limit=200, comment_limit=10, sleep_time=1):\n",
    "    \"\"\"\n",
    "    Fetch the top 10 most upvoted comments from posts on a specific topic in a given subreddit.\n",
    "    \n",
    "    Parameters:\n",
    "        subreddit_name (str): Name of the subreddit to search.\n",
    "        search_query (str): The search term to filter posts.\n",
    "        time_filter (str): Time range for the search ('day', 'week', 'month', 'year', 'all').\n",
    "        post_limit (int): Maximum number of posts to retrieve.\n",
    "        comment_limit (int): Maximum number of comments to retrieve per post.\n",
    "        sleep_time (int): Time in seconds to wait between each request batch.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing collected comment data.\n",
    "    \"\"\"\n",
    "    comments_data = []\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    print(f\"Collecting comments from posts in r/{subreddit_name} related to '{search_query}'...\")\n",
    "\n",
    "    try:\n",
    "        # Search for relevant posts\n",
    "        for post in subreddit.search(search_query, time_filter=time_filter, limit=post_limit):\n",
    "            # Set comment sort order to \"top\" to get the highest upvoted comments\n",
    "            post.comment_sort = 'top'\n",
    "            \n",
    "            # Get the post permalink to construct URLs\n",
    "            post_url = f\"https://www.reddit.com{post.permalink}\"\n",
    "\n",
    "            # Get the top comments for each post\n",
    "            post.comments.replace_more(limit=0)\n",
    "            for comment in post.comments[:comment_limit]:  # Limit to top 10 comments per post\n",
    "                if comment.body.strip():  # Only include non-empty comments\n",
    "                    # Construct the direct URL to the comment\n",
    "                    comment_url = f\"{post_url}{comment.id}\"\n",
    "\n",
    "                    # Store the comment data in a dictionary\n",
    "                    comment_info = {\n",
    "                        \"created_date\": pd.to_datetime(comment.created_utc, unit='s'),\n",
    "                        \"subreddit_id\": subreddit_name,\n",
    "                        \"search_query\": search_query,\n",
    "                        \"post_id\": post.id,\n",
    "                        \"comment_id\": comment.id,\n",
    "                        \"post_title\": post.title,\n",
    "                        \"comment_text\": comment.body,\n",
    "                        \"upvotes\": comment.ups,\n",
    "                        \"post_url\": post_url,         \n",
    "                        \"comment_url\": comment_url  \n",
    "                    }\n",
    "\n",
    "                    # Append the comment data to the list\n",
    "                    comments_data.append(comment_info)\n",
    "\n",
    "            # Sleep to prevent hitting Reddit's rate limit\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    # Handle API exceptions\n",
    "    except praw.exceptions.RedditAPIException as api_error:\n",
    "        print(f\"Rate limit or other API error: {api_error}\")\n",
    "        time.sleep(60) \n",
    "\n",
    "    # Handle other exceptions\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error occurred: {e}\")\n",
    "        time.sleep(10) \n",
    "\n",
    "    # Convert collected data to DataFrame\n",
    "    df_comments = pd.DataFrame(comments_data)\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = [\"created_date\", \"subreddit_id\", \"search_query\", \"post_id\", \"comment_id\", \n",
    "                    \"post_title\", \"comment_text\", \"upvotes\", \"post_url\", \"comment_url\"]\n",
    "    df_comments = df_comments[column_order]\n",
    "\n",
    "    return df_comments\n",
    "\n",
    "# Define parameters\n",
    "subreddit_name = 'Israel'  # Specify one subreddit\n",
    "search_query = 'Palestine'  # Single topic\n",
    "\n",
    "# Fetch comments for one subreddit and topic\n",
    "df_comments = fetch_comments(subreddit_name=subreddit_name, search_query=search_query)\n",
    "\n",
    "# Optional: Save the data to a CSV file\n",
    "df_comments.to_csv(f'data/{subreddit_name}_{search_query}_comments.csv', index=False)\n",
    "\n",
    "print(f\"Collected {len(df_comments)} comments on '{search_query}' from r/{subreddit_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputationalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
