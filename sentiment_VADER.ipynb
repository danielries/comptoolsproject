{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kalleleander/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader(text):\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "\n",
    "    return sentiment['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings (e.g., 'glove.6B.50d.txt')\n",
    "file_path_glove = '/Users/kalleleander/Documents/DTU/Bachelor/Semester 2/Signals & Data/Assignments/Exam assignment/files_light/glove.6B.100d.txt'\n",
    "\n",
    "def load_glove_embeddings(file_path, embedding_dim=100):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_vader = '/Users/kalleleander/nltk_data/sentiment/vader_lexicon/vader_lexicon.txt'\n",
    "\n",
    "def load_vader_lexicon():\n",
    "    lexicon = {}\n",
    "    with open(file_path_vader, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[0]  # Word or phrase\n",
    "                sentiment_score = float(parts[1])  # Sentiment score\n",
    "                lexicon[word] = sentiment_score\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Sentiment scoring with TF-IDF weighting and embeddings\n",
    "def compute_sentiment_with_tfidf(sentence, lexicon, embeddings, tfidf_vectorizer):\n",
    "    words = sentence.lower().split()  # Tokenize the sentence\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([sentence])\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    word_tfidf = {word: tfidf_matrix[0, idx] for idx, word in enumerate(feature_names)}\n",
    "\n",
    "    sentiment_scores = []\n",
    "    \n",
    "    for word in words:\n",
    "        tfidf_weight = word_tfidf.get(word, 1)  # Default to 1 if not in TF-IDF features\n",
    "\n",
    "        if word in lexicon:  # Direct match in lexicon\n",
    "            sentiment_scores.append(lexicon[word] * tfidf_weight)\n",
    "        elif word in embeddings:  # No match in lexicon, calculate similarity\n",
    "            best_similarity = -1\n",
    "            sentiment_score = 0\n",
    "\n",
    "            for lex_word, lex_score in lexicon.items():\n",
    "                if lex_word in embeddings:\n",
    "                    similarity = cosine_similarity(embeddings[word], embeddings[lex_word])\n",
    "                    if similarity > best_similarity:\n",
    "                        best_similarity = similarity\n",
    "                        sentiment_score = lex_score\n",
    "            \n",
    "            sentiment_scores.append(sentiment_score * tfidf_weight)\n",
    "\n",
    "    # Aggregate scores (-1 to 1 scale)\n",
    "    return np.mean(sentiment_scores) if sentiment_scores else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score: 0.08639187954496616\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load resources\n",
    "    glove_path = file_path_glove  # Adjust path to GloVe embeddings file\n",
    "    embeddings = load_glove_embeddings(glove_path)\n",
    "    lexicon = load_vader_lexicon()\n",
    "\n",
    "    # Create TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Input sentence\n",
    "    sentence = \"good excellent horrible amazing bad terrible neutral\"\n",
    "    \n",
    "    # Compute sentiment\n",
    "    sentiment = compute_sentiment_with_tfidf(sentence, lexicon, embeddings, tfidf_vectorizer)\n",
    "    print(\"Sentiment Score:\", sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
