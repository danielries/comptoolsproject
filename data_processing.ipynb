{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kalleleander/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape before processing: (16585, 10)\n",
      "Combined DataFrame shape after processing: (13317, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>comment_original</th>\n",
       "      <th>comment_vader</th>\n",
       "      <th>comment_processed</th>\n",
       "      <th>comment_no_stopwords</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>post_url</th>\n",
       "      <th>comment_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-27 15:32:33</td>\n",
       "      <td>politics</td>\n",
       "      <td>Israel</td>\n",
       "      <td>1gdcy25</td>\n",
       "      <td>lu0s0st</td>\n",
       "      <td>Bernie Sanders to voters skipping presidential...</td>\n",
       "      <td>News flash, Trump is worse on every single vot...</td>\n",
       "      <td>News flash, Trump is worse on every single vot...</td>\n",
       "      <td>news flash, trump is worse on every single vot...</td>\n",
       "      <td>news flash, trump worse every single voting is...</td>\n",
       "      <td>8981</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1gd...</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1gd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-27 15:08:10</td>\n",
       "      <td>politics</td>\n",
       "      <td>Israel</td>\n",
       "      <td>1gdcy25</td>\n",
       "      <td>lu0nkvc</td>\n",
       "      <td>Bernie Sanders to voters skipping presidential...</td>\n",
       "      <td>Protest non-voters are some of the worst type ...</td>\n",
       "      <td>Protest non voters are some of the worst type ...</td>\n",
       "      <td>protest non voters are some of the worst type ...</td>\n",
       "      <td>protest non voters worst type privileged peopl...</td>\n",
       "      <td>4186</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1gd...</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1gd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          created_date subreddit_id search_query  post_id comment_id  \\\n",
       "0  2024-10-27 15:32:33     politics       Israel  1gdcy25    lu0s0st   \n",
       "1  2024-10-27 15:08:10     politics       Israel  1gdcy25    lu0nkvc   \n",
       "\n",
       "                                          post_title  \\\n",
       "0  Bernie Sanders to voters skipping presidential...   \n",
       "1  Bernie Sanders to voters skipping presidential...   \n",
       "\n",
       "                                    comment_original  \\\n",
       "0  News flash, Trump is worse on every single vot...   \n",
       "1  Protest non-voters are some of the worst type ...   \n",
       "\n",
       "                                       comment_vader  \\\n",
       "0  News flash, Trump is worse on every single vot...   \n",
       "1  Protest non voters are some of the worst type ...   \n",
       "\n",
       "                                   comment_processed  \\\n",
       "0  news flash, trump is worse on every single vot...   \n",
       "1  protest non voters are some of the worst type ...   \n",
       "\n",
       "                                comment_no_stopwords  upvotes  \\\n",
       "0  news flash, trump worse every single voting is...     8981   \n",
       "1  protest non voters worst type privileged peopl...     4186   \n",
       "\n",
       "                                            post_url  \\\n",
       "0  https://www.reddit.com/r/politics/comments/1gd...   \n",
       "1  https://www.reddit.com/r/politics/comments/1gd...   \n",
       "\n",
       "                                         comment_url  \n",
       "0  https://www.reddit.com/r/politics/comments/1gd...  \n",
       "1  https://www.reddit.com/r/politics/comments/1gd...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataframes\n",
    "df_politics_Israel = pd.read_csv('data/politics_Israel_comments.csv')\n",
    "df_politics_Palestine = pd.read_csv('data/politics_Palestine_comments.csv')\n",
    "df_worldnews_Israel = pd.read_csv('data/worldnews_Israel_comments.csv')\n",
    "df_worldnews_Palestine = pd.read_csv('data/worldnews_Palestine_comments.csv')\n",
    "df_Israel_Israel = pd.read_csv('data/Israel_Israel_comments.csv')\n",
    "df_Israel_Palestine = pd.read_csv('data/Israel_Palestine_comments.csv')\n",
    "df_Palestine_Israel = pd.read_csv('data/Palestine_Israel_comments.csv')\n",
    "df_Palestine_Palestine = pd.read_csv('data/Palestine_Palestine_comments.csv')\n",
    "df_baking = pd.read_csv('data/baking_cake_comments.csv')\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df_combined = pd.concat([\n",
    "    df_politics_Israel, df_politics_Palestine, \n",
    "    df_worldnews_Israel, df_worldnews_Palestine, \n",
    "    df_Israel_Israel, df_Israel_Palestine, \n",
    "    df_Palestine_Israel, df_Palestine_Palestine,\n",
    "    df_baking\n",
    "])\n",
    "\n",
    "# Print initial shape\n",
    "print(f\"Combined DataFrame shape before processing: {df_combined.shape}\")\n",
    "\n",
    "# Store original text in a new column for reference\n",
    "df_combined['comment_original'] = df_combined['comment_text']\n",
    "\n",
    "# Remove duplicate comments based on 'comment_text'\n",
    "df_combined = df_combined.drop_duplicates(subset='comment_text')\n",
    "\n",
    "# Remove comments with 1 or fewer upvotes\n",
    "df_combined = df_combined[df_combined['upvotes'] > 1]\n",
    "\n",
    "# Remove URLs\n",
    "df_combined['comment_text'] = df_combined['comment_text'].apply(lambda x: re.sub(r'http\\S+|www.\\S+', '', x))\n",
    "\n",
    "# Expand contractions\n",
    "df_combined['comment_text'] = df_combined['comment_text'].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "# Remove special characters except \".\", \"!\",\"?\", and \",\"\n",
    "df_combined['comment_text'] = df_combined['comment_text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9.,!?]', ' ', x))\n",
    "\n",
    "# Remove rows where comments contains no letters\n",
    "df_combined = df_combined[df_combined['comment_text'].str.contains(r'[a-zA-Z]', regex=True)]\n",
    "\n",
    "# Renaming\n",
    "df_combined.rename(columns={'comment_text': 'comment_processed'}, inplace=True)\n",
    "\n",
    "# Remove row if processed text is below 4 words\n",
    "df_combined = df_combined[df_combined['comment_processed'].apply(lambda x: len(x.split()) > 3)]\n",
    "\n",
    "# Remove whitespaces and multiple spaces\n",
    "df_combined['comment_processed'] = df_combined['comment_processed'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Create a copy for the VADER sentiment analysis without lowercasing\n",
    "df_combined['comment_vader'] = df_combined['comment_processed']\n",
    "\n",
    "# Lowercase conversion\n",
    "df_combined['comment_processed'] = df_combined['comment_processed'].str.lower()\n",
    "\n",
    "# New column without stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df_combined['comment_no_stopwords'] = df_combined['comment_processed'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
    ")\n",
    "\n",
    "# Reorder columns\n",
    "df_combined = df_combined[['created_date', 'subreddit_id', 'search_query', 'post_id', 'comment_id', \n",
    "                           'post_title', 'comment_original', 'comment_vader', 'comment_processed', 'comment_no_stopwords', 'upvotes', \n",
    "                           'post_url', 'comment_url']]\n",
    "\n",
    "# Remove row if there is an empty field\n",
    "df_combined = df_combined.dropna()\n",
    "\n",
    "# Reset index\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print shape after processing\n",
    "print(f\"Combined DataFrame shape after processing: {df_combined.shape}\")\n",
    "\n",
    "# Display final DataFrame\n",
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example to compare original comment with processed comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/politics/comments/1gdcy25/bernie_sanders_to_voters_skipping_presidential/lu0s0st\n",
      "News flash, Trump is worse on every single voting issue. Every. Single. One.\n",
      "News flash, Trump is worse on every single voting issue. Every. Single. One.\n",
      "news flash, trump is worse on every single voting issue. every. single. one.\n",
      "news flash, trump worse every single voting issue. every. single. one.\n"
     ]
    }
   ],
   "source": [
    "# print out a comment URL and text\n",
    "print(df_combined['comment_url'].iloc[0])\n",
    "print(df_combined['comment_original'].iloc[0])\n",
    "print(df_combined['comment_vader'].iloc[0])\n",
    "print(df_combined['comment_processed'].iloc[0])\n",
    "print(df_combined['comment_no_stopwords'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply sentiment and Lix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sentiment_analysis.ipynb\n",
    "%run lix_calc_function.ipynb\n",
    "\n",
    "#Apply function LIX calculation\n",
    "df_combined['lix_score'] = df_combined['comment_processed'].apply(lix_calc_used)\n",
    "\n",
    "# Apply function to calculate sentiment score\n",
    "df_combined['sentiment_score'] = df_combined['comment_vader'].apply(calculate_sentiment_vader)\n",
    "\n",
    "# Apply log transformation to upvotes\n",
    "df_combined['log_upvotes'] = df_combined['upvotes'].apply(lambda x: np.log(x))\n",
    "\n",
    "# Apply log transformation to lix_score\n",
    "df_combined['log_lix_score'] = df_combined['lix_score'].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distributions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df_combined.copy()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(11, 11))\n",
    "cols = ['log_upvotes', 'log_lix_score', 'sentiment_score']\n",
    "df_clean = dt[cols]\n",
    "\n",
    "axes[0, 1].set_title('Unscaled data', fontsize=16)\n",
    "sns.scatterplot(ax = axes[0, 0], data=df_clean, x=\"log_upvotes\", y=\"log_lix_score\")\n",
    "sns.scatterplot(ax = axes[0, 1], data=df_clean, x=\"log_upvotes\", y=\"sentiment_score\")\n",
    "sns.scatterplot(ax = axes[0, 2], data=df_clean, x=\"sentiment_score\", y=\"log_lix_score\")\n",
    "\n",
    "sns.histplot(ax = axes[1,0], data=dt, x=\"log_upvotes\").set_title('Log Upvotes')\n",
    "sns.histplot(ax = axes[1,1], data=dt, x=\"sentiment_score\").set_title('Sentiment Score')\n",
    "sns.histplot(ax = axes[1,2], data=dt, x=\"log_lix_score\").set_title('Log Lix Score')\n",
    "\n",
    "sns.kdeplot(ax = axes[2, 0], data=df_clean, x=\"upvotes\", y=\"lix_score\", )\n",
    "sns.kdeplot(ax = axes[2, 1], data=df_clean, x=\"log_upvotes\", y=\"sentiment_score\")\n",
    "sns.kdeplot(ax = axes[2, 2], data=df_clean, x=\"sentiment_score\", y=\"log_lix_score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we export them to CSV\n",
    "subreddits = df_combined['subreddit_id'].unique()\n",
    "for subreddit in subreddits:\n",
    "    df_combined[df_combined['subreddit_id'] == subreddit].to_csv(f'data/{subreddit}_w_lix_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save whole dataframe for sentiment analysis\n",
    "df_combined.to_csv('data/sentiment/combined_preprocessed_comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
