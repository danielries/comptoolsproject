{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "df_politics_Israel = pd.read_csv('data/politics_Israel_comments.csv')\n",
    "df_politics_Palestine = pd.read_csv('data/politics_Palestine_comments.csv')\n",
    "df_worldnews_Israel = pd.read_csv('data/worldnews_Israel_comments.csv')\n",
    "df_worldnews_Palestine = pd.read_csv('data/worldnews_Palestine_comments.csv')\n",
    "df_Israel_Israel = pd.read_csv('data/Israel_Israel_comments.csv')\n",
    "df_Israel_Palestine = pd.read_csv('data/Israel_Palestine_comments.csv')\n",
    "df_Palestine_Israel = pd.read_csv('data/Palestine_Israel_comments.csv')\n",
    "df_Palestine_Palestine = pd.read_csv('data/Palestine_Palestine_comments.csv')\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df_combined = pd.concat([\n",
    "    df_politics_Israel, df_politics_Palestine, \n",
    "    df_worldnews_Israel, df_worldnews_Palestine, \n",
    "    df_Israel_Israel, df_Israel_Palestine, \n",
    "    df_Palestine_Israel, df_Palestine_Palestine\n",
    "])\n",
    "\n",
    "# Print initial shape\n",
    "print(f\"Combined DataFrame shape before processing: {df_combined.shape}\")\n",
    "\n",
    "# Store original text in a new column for reference\n",
    "df_combined['comment_original'] = df_combined['comment_text']\n",
    "\n",
    "# Remove duplicate comments based on 'comment_text'\n",
    "df_combined = df_combined.drop_duplicates(subset='comment_text')\n",
    "\n",
    "# Remove comments with 1 or fewer upvotes\n",
    "df_combined = df_combined[df_combined['upvotes'] > 1]\n",
    "\n",
    "# Remove URLs\n",
    "df_combined['comment_text'] = df_combined['comment_text'].apply(lambda x: re.sub(r'http\\S+|www.\\S+', '', x))\n",
    "\n",
    "# Expand contractions\n",
    "df_combined['comment_text'] = df_combined['comment_text'].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "# Lowercase conversion\n",
    "df_combined['comment_text'] = df_combined['comment_text'].str.lower()\n",
    "\n",
    "# Remove special characters except \".\", \"!\",\"?\", and \",\"\n",
    "df_combined['comment_text'] = df_combined['comment_text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9.,!?]', ' ', x))\n",
    "\n",
    "# Renaming\n",
    "df_combined.rename(columns={'comment_text': 'comment_processed'}, inplace=True)\n",
    "\n",
    "# Remove row if processed text is below 4 words\n",
    "df_combined = df_combined[df_combined['comment_processed'].apply(lambda x: len(x.split()) > 3)]\n",
    "\n",
    "# Remove whitespaces and multiple spaces\n",
    "df_combined['comment_processed'] = df_combined['comment_processed'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# New column without stopwords\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df_combined['comment_no_stopwords'] = df_combined['comment_processed'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
    ")\n",
    "\n",
    "# Reorder columns\n",
    "df_combined = df_combined[['created_date', 'subreddit_id', 'search_query', 'post_id', 'comment_id', \n",
    "                           'post_title', 'comment_original', 'comment_processed', 'comment_no_stopwords', 'upvotes', \n",
    "                           'post_url', 'comment_url']]\n",
    "\n",
    "# Remove row if there is an empty field\n",
    "df_combined = df_combined.dropna()\n",
    "\n",
    "# Reset index\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print shape after processing\n",
    "print(f\"Combined DataFrame shape after processing: {df_combined.shape}\")\n",
    "\n",
    "# Display final DataFrame\n",
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example to compare original comment with processed comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out a comment URL and text\n",
    "print(df_combined['comment_url'].iloc[0])\n",
    "print(df_combined['comment_original'].iloc[0])\n",
    "print(df_combined['comment_processed'].iloc[0])\n",
    "print(df_combined['comment_no_stopwords'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply sentiment and Lix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sentiment_analysis.ipynb\n",
    "%run lix_calc_function.ipynb # Use this once we have made a Lix_Calc that should only contain the function\n",
    "\n",
    "#Apply function \"lix_calc3\"\n",
    "df_combined['lix_score'] = df_combined['comment_processed'].apply(lix_calc_used)\n",
    "\n",
    "# Apply function \"calculate_sentiment\"\n",
    "df_combined['sentiment_score'] = df_combined['comment_processed'].apply(calculate_sentiment_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distributions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df_combined.copy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(11, 11))\n",
    "cols = ['upvotes', 'lix_score', 'sentiment_score']\n",
    "df_clean = dt[cols]\n",
    "\n",
    "axes[0, 1].set_title('Unscaled data', fontsize=16)\n",
    "sns.scatterplot(ax = axes[0, 0], data=df_clean, x=\"upvotes\", y=\"lix_score\")\n",
    "sns.scatterplot(ax = axes[0, 1], data=df_clean, x=\"upvotes\", y=\"sentiment_score\")\n",
    "sns.scatterplot(ax = axes[0, 2], data=df_clean, x=\"sentiment_score\", y=\"lix_score\")\n",
    "\n",
    "sns.histplot(ax = axes[1,0], data=dt, x=\"upvotes\").set_title('Upvotes')\n",
    "sns.histplot(ax = axes[1,1], data=dt, x=\"sentiment_score\").set_title('Sentiment Score')\n",
    "sns.histplot(ax = axes[1,2], data=dt, x=\"lix_score\").set_title('Lix Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which columns to save\n",
    "columns_to_save = ['created_date', 'subreddit_id', 'search_query', 'post_id', 'comment_id', \n",
    "                   'post_title', 'comment_processed', 'comment_no_stopwords', \n",
    "                   'upvotes', 'lix_score', 'sentiment_score']\n",
    "\n",
    "# Save the processed DataFrame to a CSV file\n",
    "df_combined[columns_to_save].to_csv('data/combined_comments_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we export them to CSV\n",
    "subreddits = df_combined['subreddit_id'].unique()\n",
    "for subreddit in subreddits:\n",
    "    df_combined[df_combined['subreddit_id'] == subreddit].to_csv(f'data/{subreddit}_w_lix_sentiment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputationalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
